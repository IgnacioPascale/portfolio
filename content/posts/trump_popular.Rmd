---
title: "How popular is Donald Trump?"
date: '2020-09-20'
description: Analysis on his first presidential cycle
draft: no
keywords: ''
slug: trump_popular
categories: null
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(infer)
library(ggrepel)
library(knitr)
library(ggpubr)
library(scales)
library(tidytext)
```


Mr Donald Trump is undoubtely one of the most controversial persons in the world. Some people love him, others not so much. And there's a lot going on about his approval index. 

**But how popular is, in reality, Mr. President?**

fivethirtyeight.com has detailed data on [all polls that track the president's approval ](https://projects.fivethirtyeight.com/trump-approval-ratings). You can find this information on the link.

In this blogpost, we will download the data set `approval_pollist` to analyse Mr. Trump's popularity throughout his presidential cycle. The idea is to produce a plot that will let us analyse this variable each year, and introduce an interval confidence for every point.

## Exploratory Data Analysis

Let's import our data and have a first view using `skim()`.

```{r, cache=TRUE}
# Import approval polls data
approval_polllist <- read_csv(here::here('datasets', 'approval_polllist.csv'))

skim(approval_polllist)

```


As it seems, our dataset contains a total of 14533 observations and 22 variables, from which 12 are `character` variables, 1 `logical` and 9 `numeric`.

This one also seems to be a clean data set; there are no `NA` values in our `numeric` variables, according to our `skim`. Unfortunately, our `logical` variable `tracking` is missing 8713 records, and our `character` variables `multiversions` and `grade` are missing 14463 and 485 records accordingly.

Let's now take a raw view at our data using the function `sample_n`.

```{r sample_trump, echo=TRUE}

# Take a sample size
sample_n(approval_polllist, 5)

```

The good news is that in our analysis we will not need any of the 3 variables with missing values. Therefore, we can dismiss them and continue with our analysis.

## Data wrangling

Our variables of interest are:

1. `approve`: approval rate
2. `disapprove`: disapproval rate
3. `poll_id`: poll_id
4. `enddate`: to associate the "grade" or approval to a date

First, we filter the data on the `subgroup` "Voters", as this is what we are interested in, and then `select()` our variables of interest.

```{r cleandata, echo=TRUE}

# Create new df object

df <- approval_polllist %>% 
  filter(subgroup %in% "Voters") %>% 
  select(enddate, approve, disapprove, poll_id) #include poll_id to check for duplicate polls

# Check for duplicates and missing entries
any(duplicated(df))
any(is.na(df))

glimpse(df)
```

There are neither duplicates nor missing values - as confirmed before. 

We can now wrangle the data to sort it by date, group it per week and year. For this purpose, we will use `mutate()` and the functions in the library `lubridate` that will help us manage dates. Also, we will create confindence intervals for the sample mean of the `approve`-`disapprove` - this is the population parameter we are interested in.

```{r grouped_df, echo=TRUE}
grouped_df <- df %>% 
  #get year and week number
  mutate(date = mdy(enddate), 
         weeknr = week(date), 
         yearnr = year(date)) %>%
  
  #group poll date per week
  group_by(yearnr, weeknr) %>%
  
  #summarise statistics of the grouped data
  summarise(avg_net_apr = mean(approve - disapprove), 
            std = sd(approve - disapprove), 
            count = n(), 
            t_crit = qt(.975, count-1)) %>% 
  mutate(se = std / sqrt(count),
  
  #calculate confidence interval
        upper = avg_net_apr + t_crit*se,
        lower = avg_net_apr - t_crit*se) 
  
grouped_df
```
Our data frame is now grouped by year, week and includes our `avg_net_apr` (sample mean), `std`, `se` and both `upper` and `lower` confidence intervals. We are ready to plot this.

## Plotting

Now, we can construct the plot we want to analyze.

```{r plot, echo=TRUE, fig.width=10, fig.height=10}
grouped_df %>%
  # Create ggplot
  ggplot(aes(weeknr, avg_net_apr))+
  
  #create facet wrap 
  facet_wrap(~yearnr)+
  
  #add line with dots; colour according to the year
  geom_path(aes(color = factor(yearnr))) + geom_point(aes(color = factor(yearnr)), size = 0.85) +
  
  #add band around line to display CI
  geom_ribbon(aes(ymin = lower, ymax = upper, fill = factor(yearnr), color = factor(yearnr)),
              alpha = 0.1)+ #color adds border on the edge
  
  #horizontal line on y=0
  geom_hline(yintercept=0, color = "orange")+
  
  #adjust scales
  scale_x_continuous(expand = expansion(mult = .07), #white border around line plots
                     breaks=seq(0,52,13)) + #x-axis breaks
  scale_y_continuous(breaks = breaks_extended(n=12)) + #12 breaks on y-axis
  
  #aesthetics
  theme_bw() + #black border around plots
  theme(aspect.ratio = 1/3, legend.position = "none") + 
  labs(x = "Week of the year", 
       y = "Averge Net Approval (%)", 
       title = "Trump's popularity remained steadily below 50% throughout his term", 
       subtitle = "Estimated Net Approval (approve-disapprove) for Donald Trump")
```

**What is this telling us?**

The graph shows that Trump's approval rate has decreased very rapidly below the 50% mark in the early course of his presidency, and has since then remained fairly stable at roughly 40%. 

The early weeks of 2020 show a further decrease in popularity. This coincides with the start of the corona crisis, and subsequent restricting measures imposed on the population. As these were sometimes seen as a restriction of *freedom*, they were not well tolerated by some. 

In later weeks of 2020, Trump's populariy has seen a new rise, as restrictions were lifted and the presidential election campaigns have started going at full steam.

## Comparing Confidence Intervals

Taking a look at year 2020, there's a big difference in some confidence intervals. In the first part of the year, these were narrow - however, more variability is present in the last bits. Let's analyse the the confidence intervals for `week 15` (6-12 April 2020) and `week 34` (17-23 August 2020) and see what they are telling us.

**What's going on?**

```{r}
grouped_df %>% 
  filter(weeknr == 15, yearnr == 2020) %>% 
  select(lower, upper)

grouped_df %>% 
  filter(weeknr == 34, yearnr == 2020) %>% 
  select(lower, upper)
```

It is evident that the confidence interval for week 34 is larger than for week 15. Two elements influence this difference. The first one is the difference in standard deviation: the SD for week 34 is far higher than for week 15. This means that there was more uncertainty among the polls as to the approval rate, which might be due to biased polling techniques or a general uncertainty in the public in the light of the upcoming elections. The second factor is that there are more polls available for week 15 (28 as opposed to 25 for week 34), and a higher sample size decreases the uncertainty.
